FFS (Fast File System):
FFS è un file system che è nato nel mondo UNIX parecchio tempo fa, e i file system che si utilizzano attualmente in Linux/UNIX sono evoluzioni dell’idea originale. FFS gira tutto intorno alla tabella degli 
i-Node, la struttura dati che contiene associazione tra file e blocchi in cui è contenuto. Oltre a questa associazione, l’i-Node contiene anche tanti metadati, informazioni associate ai file, inclusi i bit di protezione. Quini l’i-Node contiene metadati e puntatori. 
Dal punto di vista fisico, astrattamente, un disco Unix prevede questa struttura: i primi due blocchi sono riservati: blocco 0 è quello per il Boot (del sistema operativo), blocco 1 è il superblocco (contiene informazioni relative a questo file system, quali versione del FFS e alcuni parametri). Dopo il superblocco ci sono una serie di blocchi (della stessa dimensione) che memorizzano la tabella degli i-Node (la i-List) che quindi sono organizzati in record. Dopo l’i-List c’è la Bitmap che mappa i blocchi liberi/occupati del disco e infine troviamo i dati.
L’i-Node contiene: informazioni sulle proprietà dei file, informazioni su permessi di accesso, istante di ultimo accesso, istante di modifica, creazione, numero di hard link e tutta una serie di informazioni, poi ci sono i puntatori ai blocchi nei quali il file è allocato. Questi puntatori sono organizzati nell’i-Node usando una struttura ad albero fisso e asimmetrico: nell’i-Node son memorizzati 15 puntatori, di cui 12 puntatori sono puntatori a blocchi diretti, quindi puntano direttamente a dei blocchi dati; chiaramente se un file occupa al più 12 blocchi,  questo può essere interamente rappresentato dal suo i-Node. Se però il file è un po’ più grande, questi 12 puntatori diretti non mi bastano, dovrei avere un numero di puntatori che cresce in funzione della dimensione del file, però questo è un problema in UNIX perché gli i-Node sono strutture dati a dimensione fissa, proprio per permette di gestire bene il loro utilizzo all’interno della i-List. Per cui se il file è più lungo, i puntatori aggiuntivi ai blocchi ulteriori non sono memorizzati nell’i-Node ma sono memorizzati in alcuni blocchi dati che si trovano nel resto del disco e l’i-Node ne contiene il puntatore, in particolare l’i-Node contiene 3 puntatori a blocchi di indirizzi, che sono puntatori indiretto singolo doppio e triplo. Il primo puntatore indiretto punta a un blocco indice di terzo livello, questo blocco indice è un blocco dati (quindi potrebbe essere grosso 4 Kb o 2 Kb a seconda della dimensione dei blocchi in questo file system) e contiene puntatori a blocchi dati del disco. Il puntatore indiretto doppio punta a un blocco indice che contiene puntatori ad altrettanti blocchi indice ognuno dei quali contiene altrettanti puntatori a blocchi dati, quindi il numero di blocchi dati che indicizzo con un indirizzamento indiretto doppio, cresce di un ordine quadrato, e per il triplo è lo stesso gioco fatto tre volte.
Il risultato è che la struttura dati che rappresenta questo file è un albero asimmetrico: per il terzo puntatore abbiamo tre livelli, per il secondo puntatore due livelli, per il primo puntatore abbiamo un solo livello. La struttura è fissa perché deve crescere secondo questa struttura preordinata, non posso cambiarla. In UNIX si adotta questo modello con albero asimmetrico fisso perché questa struttura è efficiente per rappresentare file di dimensioni differenti: file piccoli son memorizzati con poche informazioni con solo 
i-Node, file medi mi richiedono un po’ più di informazioni, file grandi ne richiedono ancora di più. Quindi in qualche modo la dimensione della struttura che rappresenta un file è legata alla dimensione del file: più è grande il file, più costa la struttura in termini di Overhead di memoria e tempo di accesso. Questo permette di essere efficiente per memorizzare file piccoli e d'altra parte non penalizza la memorizzazione dei file grandi, che avranno un albero più profondo, perchè utilizzano il secondo, il terzo livello, quindi l'accesso sui file grandi è un po’ più pesante, ma d'altra parte questo è accettabile perché quando si legge un file grande si sa che si dovrà aspettare più tempo. Quindi la penalizzazione maggiore per i file grandi incide poco rispetto al tempo totale di accesso al file. 
FFS Locality
Un'ultima questione sempre legata all'FFS è l'aspetto della località. Sappiamo che per accedere efficacemente ad un file grande è necessario che tutti i suoi blocchi siano ravvicinati l'uno con l'altro, ma non solo: per leggere un file grande, devo leggere anche i suoi blocchi indice e devo leggere anche il suo i-Node. Quindi quando vado a fare l'accesso, in realtà, dovrò contare l'accesso alla directory che contiene l'i-Node, nella quale trovo il puntatore al suo i-Node, accedo al suo i-Node e a questo punto posso leggere un po' di blocchi dati, poi dovrò leggere i blocchi indice, poi dovrò leggere i blocchi dati puntati dai blocchi indice; tutte queste operazioni comportano dei seek nel disco, degli spostamenti della testina. Se voglio essere efficiente bisogna che la directory, l'i-node, i blocchi indice e i blocchi dati del file stiano tutti quanti abbastanza vicini nella stessa zona del disco. Per fare questo FFS divide il disco in macro-aree e per quanto possibile cerca di allocare un'intera directory, con tutti i file in essa contenuti, all'interno della stessa area (ovviamente nei limiti del possibile).
In questo modo un accesso ad un file o a più file della stessa directory comporta dei tempi di seek ridotti perchè ci stiamo muovendo all'interno di una stessa area del disco. Oltre a questo, utilizza un metodo di allocazione first fit, per cui va ad allocare i blocchi a gruppi in maniera tale da tenerli il più possibile vicini gli uni agli altri.
Vantaggi FFS
è efficiente nella memorizzazione, l'overhead per file piccoli è piccolo (per cui utilizzo una struttura dati ridotta);
garantisco la località per i file piccoli e grandi, per i dati ed i metadati perché tendo ad allocare all'interno dello stesso gruppo di tracce, file e directory vicini;
Può però essere inefficiente per file davvero molto piccoli, perché un file di 1 byte richiede comunque un i-Node e un blocco di dati. C'è una piccola inefficienza legata al fatto che se il file nel disco è contiguo, quindi tutti i suoi blocchi sono uno di seguito all'altro, io comunque devo memorizzare nella struttura dell'i-Node e nei blocchi indice tutti questi puntatori. In effetti se un file fosse contiguo potrei memorizzarlo in maniera molto efficace ricordandomi il blocco iniziale e la sua lunghezza, ma questa rappresentazione in FFS non è utilizzata. Mi servirebbe introdurre in FFS un concetto di superblocco, superpagina, quindi una serie di blocchi tutti contigui. 
