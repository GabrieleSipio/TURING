Segmentazione:
Lo spazio assegnato al singolo processo è composto da tanti segmenti, dove ogni segmento è una porzione di memoria contigua. Lo spazio di memoria di un processo è dato dall’unione di un certo numero di segmenti. I segmenti differenti possono essere allocati un punti differenti della memoria fisica, ne segue che non devono essere più contigui tra loro e posso avere meccanismi di protezione per ogni segmento. La segmentazione funziona nel seguente modo:
Ogni processo dispone di una tabella dei segmenti che contiene, per quel processo l’indirizzo iniziale e la lunghezza di ogni segmento allocato. Questa tabella rappresenta l’allocazione dei segmenti in memoria principale e propria del processo conservata in memoria principale (ad esempio nel descrittore del processo)
Quando il processo è in esecuzione viene presa la tabella dei segmenti e caricata all’interno della MMU
Di ogni segmento salviamo l’indirizzo fisico iniziale, la sua lunghezza e i diritti di accesso. In questo modo i processi possono condividere segmenti. La condivisione viene fatta andando ad inizializzare una riga della tabella dei segmenti in maniera identica per i due processi, così che questi ultimi puntino allo stesso segmento. Oltre a ciò ogni semento ha anche dei permessi specifici (sola lettura, sola scrittura, sola esecuzione etc..) e questo mi permettere di proteggere il codice e di impedire al programmatore di andarlo a modificare.
N.b. il caricatore non è rilocante. Quindi, quando si carica il processo per metterlo in esecuzione, si allocano i segmenti, si copia il codice eseguibile all’interno di essi e a quel punto si manda in esecuzione il processo.
Quando il processo viene compilato, un certo numero di segmenti separati, che hanno indirizzo iniziale e massimo, e i riferimenti nei confronti della memoria vedono dati a coppie (<index segmento, offset all’interno del segmento>). La traduzione nel caso di segmentazione segue i seguenti passi:
La CPU genera un indirizzo virtuale che interpreto come una coppia (<index segmento, offset>)
Se la CPU lavora a 32 bit i primi 6 codificano l’indice di segmento e i restanti 24 codificano l’indice di offset
Nell’MMU l’indice di segmento viene confrontato con un registro limite (interno all’MMU) che dice qual è il numero massimo di segmenti che quel processo sta utilizzando, quindi quando è grande la tabella dei segmenti
Se il processo sta cercando di utilizzare un segmento che non è allocato/previsto questo solleva un eccezione per la CPU e una violazione di protezione, mentre se l’indice di segmento rientra tra i segmenti allocati dal processo allora si può accedere
Si procede utilizzando l’indice di segmento per indicizzare la tabella. La MMU conosce l’indirizzo iniziale della tabella e sommando l’indice di segmento a questo indirizzo (in maniera appropriata) si va ad estrarre da questa tabella una riga in cui troviamo informazioni relative a:
Base del segmento
Limite del segmento
Diritti di accesso
La MMU fa un ulteriore operazione di protezione controllando che l’operazione eseguita sia lecita su quel segmento. Poi la MMU prende i valori della base e del limite associati al segmento e fa la seguente operazione:
Se l’offset è minore del limite allora va tutto bene e lo sommiamo alla base ottenendo un indirizzo fisico che spediamo alla memoria
Se l’offset è generato dall’indirizzo è maggiore del limite vuol dire che stiamo cercando di indirizzare una locazione di quel segmento che accede altre al limite del segmento quindi violiamo la protezione
N.b. il SO può permettere a 2 o più processi di utilizzare lo stesso segmento
 La tabella dei segmenti è collocata in memoria principale perché quando un processo non è in esecuzione è per forza lì. Il processo, quando viene messo in esecuzione, non  è solo in memoria principale ma la sua tabella dei segmenti viene caricata all’interno della MMU. Questo possiamo farlo in quanto le tabelle dei segmenti sono piccole.
Unix Fork Copy on Write:
Per generare il figlio, il SO deve duplicare tutte le strutture del nucleo associate al padre, ma non solo; deve anche duplicare la memoria. Quindi prende lo spazio di memoria associato al padre e ne fa una copia affinché il figlio lo possa utilizzare (con codice, dati e stack). Tutto questo è un enorme spreco di tempo perché, in effetti, prima che il figlio inizi a lavorare, questa memoria è esattamente la stessa e tra l’altro il figlio potrebbe anche non modificarne né il codice né  dati né stack. Potrei fare una exec e poi dopo devo di nuovo ricambiare tutto quanto.  Se, invece, il figlio non fa una exec comunque il codice resta uguale. Per questo motivo con la segmentazione si può ottimizzare pesantemente la Fork utilizzando la tecnica della copy on write. Quest’ultima è una implementazione più efficiente della Fork. Quando si fa la Fork si vanno prima di tutto a duplicare le strutture dati, quindi si duplica il descrittore del processo, si alloca una tabella dei segmenti per il figlio e tale tabella si inizializza esattamente identica a quella del padre. Ciò vuol dire che, quando il figlio andrà in esecuzione, utilizzerà la tabella dei segmenti identica a quella del padre per riferire la sua memoria e di conseguenza andrà ad accedere alla stessa memoria del padre. In questa maniera non abbiamo bisogno di fare una copia della memorai perché il figlio potrà tranquillamente andare ad accedere alla stessa memoria del padre. Il problema salta fuori se il figlio e il padre iniziano a fare accessi in scrittura; a questo punto potrebbero interferire l’uno con l’altro, questo lo devo impedire. Quando faccio la Fork marco tutti i segmenti utilizzabili in sola lettura, per cui non ho bisogno di copiare memoria: figlio e padre possono andare avanti se devono leggere la memoria, ma se qualcuno dei due la scrive causa un’eccezione. Quest’ultima, quando viene intercettata dal SO non produce segmentation fault perché il SO si è tenuto a mente il fatto che un processo ha eseguito la Fork mentre l’altro l’ha “subita”. Per cui il SO sa che in questo caso la violazione di protezione è in realtà un effetto della copy on write che ha già disabilitato i diritti di scrittura. Quindi soltanto in questa circostanza il SO prende il segmento e lo duplica. Fatto questo ripristina i diritti originari di entrambi i segmenti e, da questo punto, il processo padre e il processo figlio possono continuare ad andare avanti, modificando stavolta la copia della loro memoria, non l’originale. Il vantaggi sta nel fatto che non devo duplicare ogni volta tutti i segmenti, ma solo i segmenti dati e i segmenti stack dei processi che devono fare operazioni di scrittura.
Zero-on-Reference:
Quando si carica un processo per l’esecuzione, quanta memoria dovete allocare per lo stack e quanta per lo heap? Per il codice è facile, in quanto è stato compilato e sapete esattamente quante sono le istruzioni, quanto occupano etc. Però, i dati dinamici, non sappiamo quanti saranno, non sappiamo quanto dovrà crescere lo heap. Quindi quando andiamo ad analizzare un processo e dobbiamo allocare il segmento per lo heap e per lo stack, quanto ne allochiamo? Zero. Possiamo non allocarlo, perché, non appena il processo va a toccare il segmento stack, poi il segmento heap, capiamo che quel segmento va allargato. Il processo ha diritto ad allargare il suo segmento heap/stack (sono strutture che si devono allargare dinamicamente). Quindi andare a riferire il segmento heap/stack non è un problema se non è stato allocato. Si procede come segue:
Si inizializza un stack/heap di dimensione pari al main (nello stack c’è sicuramente quel record di attivazione)
Proibiamo l’accesso nel momento nel quale il processo fa riferimento a quel segmento
Si invoca una chiamata di sistema per allargare il segmento
N.b. il numero di segmenti che utilizzo per allocare heap, stack etc.. non dipende dal SO, ma dipende molto dal linguaggio. Perché è il linguaggio in fase di compilazione e linking che decide quanti sono i segmenti. Ed è il RTS che, a tempo di esecuzione, riceve la malloc e che poi le implementa con le chiamate di sistema sottostanti e che decide se deve allocare un nuovo segmento oppure no.
Vantaggi e svantaggi della segmentazione:
Vantaggi:
Possiamo condividere codice
Possiamo avere dei meccanismi di protezione differenziati a seconda del segmento
Possiamo proteggere il codice impedendo che venga sovrascritto
Possiamo sfruttare questi meccanismi per fare la copy on write rendendo la Fork più efficiente
Svantaggi:
Gestione della memoria è più complessa (non abbiamo solo due registri ma un’intera tabella di registri da dover gestire e caricare nella MMU)
Dobbiamo avere un meccanismo per allocare la memoria fisica, questo anche se usiamo il Basa & Bound, ma va applicato più volte. 
I segmenti vengono allocati in modo sparpagliato per la dimensione di cui hanno bisogno e spesso può capitare che rimanga un residuo di memoria nello slot libero, perché alloca meno memoria dell’intero blocco libero che però è troppo piccola per essere allocata per un altro segmento. Ne segue che la memoria, pur avendo spazio libero, lo ha in maniera frammentata in porzioni troppo piccole per poter ospitare ulteriori segmenti e quindi, in caso di allocazione di un nuovo segmento, si è costretti ad usare la memoria principale e questo è molto dispendioso. 
La gestione della memoria fisica non è sufficientemente efficiente a causa della frammentazione (frammentazione esterna)
Si potrebbe necessitare di riallocare la memoria per fare eventualmente spazio a nuovi segmenti o segmenti in crescita   
